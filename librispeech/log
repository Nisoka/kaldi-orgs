liujunnan@innovem:/data/home/liujunnan/librispeech/ctc$ ./run.sh
local/download_and_untar.sh: data part dev-clean was already successfully extracted, nothing to do.
local/download_and_untar.sh: data part test-clean was already successfully extracted, nothing to do.
local/download_and_untar.sh: data part dev-other was already successfully extracted, nothing to do.
local/download_and_untar.sh: data part test-other was already successfully extracted, nothing to do.
local/download_and_untar.sh: data part train-clean-100 was already successfully extracted, nothing to do.
local/download_and_untar.sh: data part train-clean-360 was already successfully extracted, nothing to do.
local/download_and_untar.sh: data part train-other-500 was already successfully extracted, nothing to do.
Downloading file '3-gram.arpa.gz' into 'data/local/lm'...
--2018-04-17 11:00:24--  http://www.openslr.org/resources/11/3-gram.arpa.gz
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 759636181 (724M) [application/x-gzip]
Saving to: 'data/local/lm/3-gram.arpa.gz'

data/local/lm/3-gram.arpa.gz      100%[=============================================================>] 724.45M  6.70MB/s    in 1m 47s  

2018-04-17 11:02:11 (6.75 MB/s) - 'data/local/lm/3-gram.arpa.gz' saved [759636181/759636181]

Downloading file '3-gram.pruned.1e-7.arpa.gz' into 'data/local/lm'...
--2018-04-17 11:02:11--  http://www.openslr.org/resources/11/3-gram.pruned.1e-7.arpa.gz
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 34094057 (33M) [application/x-gzip]
Saving to: 'data/local/lm/3-gram.pruned.1e-7.arpa.gz'

data/local/lm/3-gram.pruned.1e-7. 100%[=============================================================>]  32.51M  4.89MB/s    in 8.3s    

2018-04-17 11:02:20 (3.92 MB/s) - 'data/local/lm/3-gram.pruned.1e-7.arpa.gz' saved [34094057/34094057]

Downloading file '3-gram.pruned.3e-7.arpa.gz' into 'data/local/lm'...
--2018-04-17 11:02:20--  http://www.openslr.org/resources/11/3-gram.pruned.3e-7.arpa.gz
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 13654242 (13M) [application/x-gzip]
Saving to: 'data/local/lm/3-gram.pruned.3e-7.arpa.gz'

data/local/lm/3-gram.pruned.3e-7. 100%[=============================================================>]  13.02M  3.27MB/s    in 4.0s    

2018-04-17 11:02:25 (3.27 MB/s) - 'data/local/lm/3-gram.pruned.3e-7.arpa.gz' saved [13654242/13654242]

Downloading file '4-gram.arpa.gz' into 'data/local/lm'...
--2018-04-17 11:02:25--  http://www.openslr.org/resources/11/4-gram.arpa.gz
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1355172078 (1.3G) [application/x-gzip]
Saving to: 'data/local/lm/4-gram.arpa.gz'

data/local/lm/4-gram.arpa.gz      100%[=============================================================>]   1.26G  4.10MB/s    in 3m 31s  

2018-04-17 11:05:57 (6.12 MB/s) - 'data/local/lm/4-gram.arpa.gz' saved [1355172078/1355172078]

Downloading file 'g2p-model-5' into 'data/local/lm'...
--2018-04-17 11:05:57--  http://www.openslr.org/resources/11/g2p-model-5
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 20098243 (19M)
Saving to: 'data/local/lm/g2p-model-5'

data/local/lm/g2p-model-5         100%[=============================================================>]  19.17M  4.62MB/s    in 5.7s    

2018-04-17 11:06:03 (3.38 MB/s) - 'data/local/lm/g2p-model-5' saved [20098243/20098243]

Downloading file 'librispeech-lm-corpus.tgz' into 'data/local/lm'...
--2018-04-17 11:06:03--  http://www.openslr.org/resources/11/librispeech-lm-corpus.tgz
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1803499244 (1.7G) [application/x-gzip]
Saving to: 'data/local/lm/librispeech-lm-corpus.tgz'

data/local/lm/librispeech-lm-corp 100%[=============================================================>]   1.68G  5.07MB/s    in 5m 57s  

2018-04-17 11:12:00 (4.82 MB/s) - 'data/local/lm/librispeech-lm-corpus.tgz' saved [1803499244/1803499244]

Downloading file 'librispeech-vocab.txt' into 'data/local/lm'...
--2018-04-17 11:12:00--  http://www.openslr.org/resources/11/librispeech-vocab.txt
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1737588 (1.7M) [text/plain]
Saving to: 'data/local/lm/librispeech-vocab.txt'

data/local/lm/librispeech-vocab.t 100%[=============================================================>]   1.66M  1.12MB/s    in 1.5s    

2018-04-17 11:12:02 (1.12 MB/s) - 'data/local/lm/librispeech-vocab.txt' saved [1737588/1737588]

Downloading file 'librispeech-lexicon.txt' into 'data/local/lm'...
--2018-04-17 11:12:02--  http://www.openslr.org/resources/11/librispeech-lexicon.txt
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 5627653 (5.4M) [text/plain]
Saving to: 'data/local/lm/librispeech-lexicon.txt'

data/local/lm/librispeech-lexicon 100%[=============================================================>]   5.37M  2.21MB/s    in 2.4s    

2018-04-17 11:12:05 (2.21 MB/s) - 'data/local/lm/librispeech-lexicon.txt' saved [5627653/5627653]

utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/dev_clean/wav.scp ark,t:data/dev_clean/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 2703 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 7.17578, min and max durations were 1.445, 32.645
utils/data/get_utt2dur.sh: computed data/dev_clean/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/dev_clean
local/data_prep.sh: successfully prepared data in data/dev_clean
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/test_clean/wav.scp ark,t:data/test_clean/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 2620 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 7.42461, min and max durations were 1.285, 34.955
utils/data/get_utt2dur.sh: computed data/test_clean/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/test_clean
local/data_prep.sh: successfully prepared data in data/test_clean
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/dev_other/wav.scp ark,t:data/dev_other/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 2864 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 6.43724, min and max durations were 1.065, 35.155
utils/data/get_utt2dur.sh: computed data/dev_other/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/dev_other
local/data_prep.sh: successfully prepared data in data/dev_other
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/test_other/wav.scp ark,t:data/test_other/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 2939 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 6.5429, min and max durations were 1.25, 34.51
utils/data/get_utt2dur.sh: computed data/test_other/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/test_other
local/data_prep.sh: successfully prepared data in data/test_other
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/train_clean_100/wav.scp ark,t:data/train_clean_100/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 28539 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 12.6889, min and max durations were 1.41, 24.525
utils/data/get_utt2dur.sh: computed data/train_clean_100/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/train_clean_100
local/data_prep.sh: successfully prepared data in data/train_clean_100
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/train_clean_360/wav.scp ark,t:data/train_clean_360/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 104014 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 12.5847, min and max durations were 1.065, 29.735
utils/data/get_utt2dur.sh: computed data/train_clean_360/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/train_clean_360
local/data_prep.sh: successfully prepared data in data/train_clean_360
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration --read-entire-file=false scp:data/train_other_500/wav.scp ark,t:data/train_other_500/utt2dur 
LOG (wav-to-duration:main():wav-to-duration.cc:90) Printed duration for 148688 audio files.
LOG (wav-to-duration:main():wav-to-duration.cc:92) Mean duration was 12.0298, min and max durations were 0.83, 27.92
utils/data/get_utt2dur.sh: computed data/train_other_500/utt2dur
utils/validate_data_dir.sh: Successfully validated data-directory data/train_other_500
local/data_prep.sh: successfully prepared data in data/train_other_500
Preparing phone lists and clustering questions
2 silence phones saved to: data/local/dict_nosp/silence_phones.txt
1 optional silence saved to: data/local/dict_nosp/optional_silence.txt
39 non-silence phones saved to: data/local/dict_nosp/nonsilence_phones.txt
2 extra triphone clustering-related questions saved to: data/local/dict_nosp/extra_questions.txt
Lexicon text file saved as: data/local/dict_nosp/lexicon.txt
utils/prepare_lang.sh --share-silence-phones true --position-dependent-phones false data/local/dict_nosp <UNK> data/local/lang_tmp_nosp data/lang_nosp
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> reading data/local/dict_nosp/extra_questions.txt
--> data/local/dict_nosp/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
fstaddselfloops data/lang_nosp/phones/wdisambig_phones.int data/lang_nosp/phones/wdisambig_words.int 
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp
Checking data/lang_nosp/phones.txt ...
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> 2 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> 39 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> 2 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> 21 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> 40 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> 40 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> 2 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking data/lang_nosp/oov.{txt, int} ...
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_nosp_test_tgsmall/words.txt - data/lang_nosp_test_tgsmall/G.fst 
LOG (arpa2fst:Read():arpa-file-parser.cc:90) Reading \data\ section.
LOG (arpa2fst:Read():arpa-file-parser.cc:145) Reading \1-grams: section.
LOG (arpa2fst:Read():arpa-file-parser.cc:145) Reading \2-grams: section.
LOG (arpa2fst:Read():arpa-file-parser.cc:145) Reading \3-grams: section.
LOG (arpa2fst:RemoveRedundantStates():arpa-lm-compiler.cc:341) Reduced num-states from 1183418 to 249533
utils/validate_lang.pl data/lang_nosp_test_tgsmall
Checking data/lang_nosp_test_tgsmall/phones.txt ...
--> data/lang_nosp_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang_nosp_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang_nosp_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> 2 entry/entries in data/lang_nosp_test_tgsmall/phones/context_indep.txt
--> data/lang_nosp_test_tgsmall/phones/context_indep.int corresponds to data/lang_nosp_test_tgsmall/phones/context_indep.txt
--> data/lang_nosp_test_tgsmall/phones/context_indep.csl corresponds to data/lang_nosp_test_tgsmall/phones/context_indep.txt
--> data/lang_nosp_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> 39 entry/entries in data/lang_nosp_test_tgsmall/phones/nonsilence.txt
--> data/lang_nosp_test_tgsmall/phones/nonsilence.int corresponds to data/lang_nosp_test_tgsmall/phones/nonsilence.txt
--> data/lang_nosp_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_nosp_test_tgsmall/phones/nonsilence.txt
--> data/lang_nosp_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/silence.{txt, int, csl} ...
--> 2 entry/entries in data/lang_nosp_test_tgsmall/phones/silence.txt
--> data/lang_nosp_test_tgsmall/phones/silence.int corresponds to data/lang_nosp_test_tgsmall/phones/silence.txt
--> data/lang_nosp_test_tgsmall/phones/silence.csl corresponds to data/lang_nosp_test_tgsmall/phones/silence.txt
--> data/lang_nosp_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.int corresponds to data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> 21 entry/entries in data/lang_nosp_test_tgsmall/phones/disambig.txt
--> data/lang_nosp_test_tgsmall/phones/disambig.int corresponds to data/lang_nosp_test_tgsmall/phones/disambig.txt
--> data/lang_nosp_test_tgsmall/phones/disambig.csl corresponds to data/lang_nosp_test_tgsmall/phones/disambig.txt
--> data/lang_nosp_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgsmall/phones/roots.{txt, int} ...
--> 40 entry/entries in data/lang_nosp_test_tgsmall/phones/roots.txt
--> data/lang_nosp_test_tgsmall/phones/roots.int corresponds to data/lang_nosp_test_tgsmall/phones/roots.txt
--> data/lang_nosp_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_nosp_test_tgsmall/phones/sets.{txt, int} ...
--> 40 entry/entries in data/lang_nosp_test_tgsmall/phones/sets.txt
--> data/lang_nosp_test_tgsmall/phones/sets.int corresponds to data/lang_nosp_test_tgsmall/phones/sets.txt
--> data/lang_nosp_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_nosp_test_tgsmall/phones/extra_questions.{txt, int} ...
--> 2 entry/entries in data/lang_nosp_test_tgsmall/phones/extra_questions.txt
--> data/lang_nosp_test_tgsmall/phones/extra_questions.int corresponds to data/lang_nosp_test_tgsmall/phones/extra_questions.txt
--> data/lang_nosp_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp_test_tgsmall/phones/optional_silence.txt
--> data/lang_nosp_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word-level disambiguation symbols...
--> data/lang_nosp_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking data/lang_nosp_test_tgsmall/oov.{txt, int} ...
--> 1 entry/entries in data/lang_nosp_test_tgsmall/oov.txt
--> data/lang_nosp_test_tgsmall/oov.int corresponds to data/lang_nosp_test_tgsmall/oov.txt
--> data/lang_nosp_test_tgsmall/oov.{txt, int} are OK

--> data/lang_nosp_test_tgsmall/L.fst is olabel sorted
--> data/lang_nosp_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_nosp_test_tgsmall/G.fst is ilabel sorted
--> data/lang_nosp_test_tgsmall/G.fst has 249533 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_nosp_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_nosp_test_tgsmall]
arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_nosp_test_tgmed/words.txt - data/lang_nosp_test_tgmed/G.fst 
LOG (arpa2fst:Read():arpa-file-parser.cc:90) Reading \data\ section.
LOG (arpa2fst:Read():arpa-file-parser.cc:145) Reading \1-grams: section.
LOG (arpa2fst:Read():arpa-file-parser.cc:145) Reading \2-grams: section.
LOG (arpa2fst:Read():arpa-file-parser.cc:145) Reading \3-grams: section.
LOG (arpa2fst:RemoveRedundantStates():arpa-lm-compiler.cc:341) Reduced num-states from 2610890 to 597083
utils/validate_lang.pl data/lang_nosp_test_tgmed
Checking data/lang_nosp_test_tgmed/phones.txt ...
--> data/lang_nosp_test_tgmed/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang_nosp_test_tgmed/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang_nosp_test_tgmed/phones/context_indep.{txt, int, csl} ...
--> 2 entry/entries in data/lang_nosp_test_tgmed/phones/context_indep.txt
--> data/lang_nosp_test_tgmed/phones/context_indep.int corresponds to data/lang_nosp_test_tgmed/phones/context_indep.txt
--> data/lang_nosp_test_tgmed/phones/context_indep.csl corresponds to data/lang_nosp_test_tgmed/phones/context_indep.txt
--> data/lang_nosp_test_tgmed/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgmed/phones/nonsilence.{txt, int, csl} ...
--> 39 entry/entries in data/lang_nosp_test_tgmed/phones/nonsilence.txt
--> data/lang_nosp_test_tgmed/phones/nonsilence.int corresponds to data/lang_nosp_test_tgmed/phones/nonsilence.txt
--> data/lang_nosp_test_tgmed/phones/nonsilence.csl corresponds to data/lang_nosp_test_tgmed/phones/nonsilence.txt
--> data/lang_nosp_test_tgmed/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgmed/phones/silence.{txt, int, csl} ...
--> 2 entry/entries in data/lang_nosp_test_tgmed/phones/silence.txt
--> data/lang_nosp_test_tgmed/phones/silence.int corresponds to data/lang_nosp_test_tgmed/phones/silence.txt
--> data/lang_nosp_test_tgmed/phones/silence.csl corresponds to data/lang_nosp_test_tgmed/phones/silence.txt
--> data/lang_nosp_test_tgmed/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgmed/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang_nosp_test_tgmed/phones/optional_silence.txt
--> data/lang_nosp_test_tgmed/phones/optional_silence.int corresponds to data/lang_nosp_test_tgmed/phones/optional_silence.txt
--> data/lang_nosp_test_tgmed/phones/optional_silence.csl corresponds to data/lang_nosp_test_tgmed/phones/optional_silence.txt
--> data/lang_nosp_test_tgmed/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgmed/phones/disambig.{txt, int, csl} ...
--> 21 entry/entries in data/lang_nosp_test_tgmed/phones/disambig.txt
--> data/lang_nosp_test_tgmed/phones/disambig.int corresponds to data/lang_nosp_test_tgmed/phones/disambig.txt
--> data/lang_nosp_test_tgmed/phones/disambig.csl corresponds to data/lang_nosp_test_tgmed/phones/disambig.txt
--> data/lang_nosp_test_tgmed/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp_test_tgmed/phones/roots.{txt, int} ...
--> 40 entry/entries in data/lang_nosp_test_tgmed/phones/roots.txt
--> data/lang_nosp_test_tgmed/phones/roots.int corresponds to data/lang_nosp_test_tgmed/phones/roots.txt
--> data/lang_nosp_test_tgmed/phones/roots.{txt, int} are OK

Checking data/lang_nosp_test_tgmed/phones/sets.{txt, int} ...
--> 40 entry/entries in data/lang_nosp_test_tgmed/phones/sets.txt
--> data/lang_nosp_test_tgmed/phones/sets.int corresponds to data/lang_nosp_test_tgmed/phones/sets.txt
--> data/lang_nosp_test_tgmed/phones/sets.{txt, int} are OK

Checking data/lang_nosp_test_tgmed/phones/extra_questions.{txt, int} ...
--> 2 entry/entries in data/lang_nosp_test_tgmed/phones/extra_questions.txt
--> data/lang_nosp_test_tgmed/phones/extra_questions.int corresponds to data/lang_nosp_test_tgmed/phones/extra_questions.txt
--> data/lang_nosp_test_tgmed/phones/extra_questions.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp_test_tgmed/phones/optional_silence.txt
--> data/lang_nosp_test_tgmed/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp_test_tgmed/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp_test_tgmed/phones/disambig.txt is OK

Checking topo ...

Checking word-level disambiguation symbols...
--> data/lang_nosp_test_tgmed/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking data/lang_nosp_test_tgmed/oov.{txt, int} ...
--> 1 entry/entries in data/lang_nosp_test_tgmed/oov.txt
--> data/lang_nosp_test_tgmed/oov.int corresponds to data/lang_nosp_test_tgmed/oov.txt
--> data/lang_nosp_test_tgmed/oov.{txt, int} are OK

--> data/lang_nosp_test_tgmed/L.fst is olabel sorted
--> data/lang_nosp_test_tgmed/L_disambig.fst is olabel sorted
--> data/lang_nosp_test_tgmed/G.fst is ilabel sorted
--> data/lang_nosp_test_tgmed/G.fst has 597083 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_nosp_test_tgmed/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_nosp_test_tgmed]
Succeeded in formatting data.
utils/combine_data.sh data/train_960 data/train_clean_100 data/train_clean_360 data/train_other_500
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 281241 utterances.
fix_data_dir.sh: old files are kept in data/train_960/.backup
steps/make_mfcc.sh --cmd run.pl --nj 20 --mfcc-config conf/mfcc.conf data/train_960
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for train_960
steps/compute_cmvn_stats.sh data/train_960
Succeeded creating CMVN stats for train_960
utils/subset_data_dir.sh: reducing #utt from 281241 to 100000
steps/make_mfcc.sh --cmd run.pl --nj 20 --mfcc-config conf/mfcc.conf data/test_clean
utils/validate_data_dir.sh: Successfully validated data-directory data/test_clean
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for test_clean
steps/compute_cmvn_stats.sh data/test_clean
Succeeded creating CMVN stats for test_clean
steps/make_mfcc.sh --cmd run.pl --nj 20 --mfcc-config conf/mfcc.conf data/test_other
utils/validate_data_dir.sh: Successfully validated data-directory data/test_other
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for test_other
steps/compute_cmvn_stats.sh data/test_other
Succeeded creating CMVN stats for test_other
steps/make_mfcc.sh --cmd run.pl --nj 20 --mfcc-config conf/mfcc.conf data/dev_clean
utils/validate_data_dir.sh: Successfully validated data-directory data/dev_clean
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for dev_clean
steps/compute_cmvn_stats.sh data/dev_clean
Succeeded creating CMVN stats for dev_clean
steps/make_mfcc.sh --cmd run.pl --nj 20 --mfcc-config conf/mfcc.conf data/dev_other
utils/validate_data_dir.sh: Successfully validated data-directory data/dev_other
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for dev_other
steps/compute_cmvn_stats.sh data/dev_other
Succeeded creating CMVN stats for dev_other
steps/train_mono.sh --boost-silence 1.25 --nj 20 --cmd run.pl data/train_100k data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
173745 warnings in exp/mono/log/align.*.*.log
47938 warnings in exp/mono/log/acc.*.*.log
exp/mono: nj=20 align prob=-101.53 over 341.07h [retry=0.5%, fail=0.0%] states=122 gauss=995
steps/train_mono.sh: Done training monophone system in exp/mono
steps/align_si.sh --boost-silence 1.25 --nj 20 --cmd run.pl data/train_100k data/lang_nosp exp/mono exp/mono_ali_100k
tree-info exp/mono/tree 
tree-info exp/mono/tree 
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_100k using model from exp/mono, putting alignments in exp/mono_ali_100k
fsttablecompose data/lang_nosp_test_tgsmall/L_disambig.fst data/lang_nosp_test_tgsmall/G.fst 
fstminimizeencoded 
fstpushspecial 
fstdeterminizestar --use-log=true 
fstisstochastic data/lang_nosp_test_tgsmall/tmp/LG.fst 
-0.0559239 -0.0566608
[info]: LG not stochastic.
fstcomposecontext --context-size=1 --central-position=0 --read-disambig-syms=data/lang_nosp_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_nosp_test_tgsmall/tmp/disambig_ilabels_1_0.int data/lang_nosp_test_tgsmall/tmp/ilabels_1_0 
fstisstochastic data/lang_nosp_test_tgsmall/tmp/CLG_1_0.fst 
-0.0559239 -0.0566608
[info]: CLG not stochastic.
make-h-transducer --ctc=false --disambig-syms-out=exp/mono/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_1_0 exp/mono/tree exp/mono/final.mdl 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fstrmsymbols exp/mono/graph_nosp_tgsmall/disambig_tid.int 
fstrmepslocal 
fsttablecompose exp/mono/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_1_0.fst 
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono_ali_100k
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_100k/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl 2000 10000 data/train_100k data/lang_nosp exp/mono_ali_100k exp/tri1
steps/train_deltas.sh: accumulating tree stats
fstisstochastic exp/mono/graph_nosp_tgsmall/HCLGa.fst 
0.000437692 -0.112842
HCLGa is not stochastic
add-self-loops --ctc=false --self-loop-scale=0.1 --reorder=true exp/mono/final.mdl 
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_100k to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/decode.sh --nj 10 --cmd run.pl exp/mono/graph_nosp_tgsmall data/test_clean exp/mono/decode_nosp_tgsmall_test_clean
decode.sh: feature type is delta
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
3186 warnings in exp/tri1/log/align.*.*.log
157 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/compile_questions.log
exp/tri1: nj=20 align prob=-99.92 over 341.07h [retry=0.9%, fail=0.0%] states=1612 gauss=10027 tree-impr=4.03
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
steps/align_si.sh --nj 20 --cmd run.pl data/train_100k data/lang_nosp exp/tri1 exp/tri1_ali_100k
tree-info exp/tri1/tree 
tree-info exp/tri1/tree 
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang_nosp_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_nosp_test_tgsmall/tmp/disambig_ilabels_3_1.int data/lang_nosp_test_tgsmall/tmp/ilabels_3_1 
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_100k using model from exp/tri1, putting alignments in exp/tri1_ali_100k
fstisstochastic data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst 
0 -0.0566608
[info]: CLG not stochastic.
make-h-transducer --ctc=false --disambig-syms-out=exp/tri1/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_3_1 exp/tri1/tree exp/tri1/final.mdl 
fstdeterminizestar --use-log=true 
fstrmsymbols exp/tri1/graph_nosp_tgsmall/disambig_tid.int 
fsttablecompose exp/tri1/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstrmepslocal 
fstisstochastic exp/tri1/graph_nosp_tgsmall/HCLGa.fst 
0.000488162 -0.161121
HCLGa is not stochastic
add-self-loops --ctc=false --self-loop-scale=0.1 --reorder=true exp/tri1/final.mdl 
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1_ali_100k
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_100k/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --cmd run.pl --splice-opts --left-context=3 --right-context=3 2500 15000 data/train_100k data/lang_nosp exp/tri1_ali_100k exp/tri2b
Accumulating LDA statistics.
steps/decode.sh --nj 10 --cmd run.pl exp/tri1/graph_nosp_tgsmall data/test_clean exp/tri1/decode_nosp_tgsmall_test_clean
decode.sh: feature type is delta
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri1_ali_100k to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_nosp_tgsmall exp/mono/decode_nosp_tgsmall_test_clean
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_test_clean/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(5,54,316) and mean=120.4
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_test_clean/log/analyze_lattice_depth_stats.log
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph_nosp_tgsmall exp/tri1/decode_nosp_tgsmall_test_clean
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_test_clean/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,8,53) and mean=21.0
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_test_clean/log/analyze_lattice_depth_stats.log
Training pass 31
steps/decode.sh --nj 10 --cmd run.pl exp/tri1/graph_nosp_tgsmall data/test_other exp/tri1/decode_nosp_tgsmall_test_other
decode.sh: feature type is delta
steps/decode.sh --nj 10 --cmd run.pl exp/mono/graph_nosp_tgsmall data/test_other exp/mono/decode_nosp_tgsmall_test_other
decode.sh: feature type is delta
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log
402 warnings in exp/tri2b/log/acc.*.*.log
3697 warnings in exp/tri2b/log/align.*.*.log
1 warnings in exp/tri2b/log/compile_questions.log
3 warnings in exp/tri2b/log/lda_acc.*.log
exp/tri2b: nj=20 align prob=-49.96 over 341.07h [retry=0.9%, fail=0.0%] states=2114 gauss=15034 tree-impr=4.43 lda-sum=17.82 mllt:impr,logdet=1.01,1.40
Done training system with LDA+MLLT features in exp/tri2b
tree-info exp/tri2b/tree 
tree-info exp/tri2b/tree 
make-h-transducer --ctc=false --disambig-syms-out=exp/tri2b/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_3_1 exp/tri2b/tree exp/tri2b/final.mdl 
fstrmepslocal 
fsttablecompose exp/tri2b/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst 
fstrmsymbols exp/tri2b/graph_nosp_tgsmall/disambig_tid.int 
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fstisstochastic exp/tri2b/graph_nosp_tgsmall/HCLGa.fst 
0.000488043 -0.161121
HCLGa is not stochastic
add-self-loops --ctc=false --self-loop-scale=0.1 --reorder=true exp/tri2b/final.mdl 
steps/decode.sh --nj 10 --cmd run.pl exp/tri2b/graph_nosp_tgsmall data/test_clean exp/tri2b/decode_nosp_tgsmall_test_clean
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2b/graph_nosp_tgsmall exp/tri2b/decode_nosp_tgsmall_test_clean
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_test_clean/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,35) and mean=14.1
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_test_clean/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/tri2b/graph_nosp_tgsmall data/test_other exp/tri2b/decode_nosp_tgsmall_test_other
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph_nosp_tgsmall exp/tri1/decode_nosp_tgsmall_test_other
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_test_other/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,32,171) and mean=67.3
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_test_other/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/tri1/graph_nosp_tgsmall data/dev_clean exp/tri1/decode_nosp_tgsmall_dev_clean
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2b/graph_nosp_tgsmall exp/tri2b/decode_nosp_tgsmall_test_other
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_test_other/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,22,131) and mean=50.1
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_test_other/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/tri2b/graph_nosp_tgsmall data/dev_clean exp/tri2b/decode_nosp_tgsmall_dev_clean
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_nosp_tgsmall exp/mono/decode_nosp_tgsmall_test_other
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_test_other/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(17,141,571) and mean=236.5
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_test_other/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/mono/graph_nosp_tgsmall data/dev_clean exp/mono/decode_nosp_tgsmall_dev_clean
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph_nosp_tgsmall exp/tri1/decode_nosp_tgsmall_dev_clean
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_dev_clean/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,8,59) and mean=22.7
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_dev_clean/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/tri1/graph_nosp_tgsmall data/dev_other exp/tri1/decode_nosp_tgsmall_dev_other
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2b/graph_nosp_tgsmall exp/tri2b/decode_nosp_tgsmall_dev_clean
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_dev_clean/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,37) and mean=14.7
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_dev_clean/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/tri2b/graph_nosp_tgsmall data/dev_other exp/tri2b/decode_nosp_tgsmall_dev_other
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2b/graph_nosp_tgsmall exp/tri2b/decode_nosp_tgsmall_dev_other
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_dev_other/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(2,21,124) and mean=47.8
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_dev_other/log/analyze_lattice_depth_stats.log
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph_nosp_tgsmall exp/tri1/decode_nosp_tgsmall_dev_other
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_dev_other/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,32,175) and mean=67.7
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_dev_other/log/analyze_lattice_depth_stats.log
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_nosp_tgsmall exp/mono/decode_nosp_tgsmall_dev_clean
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_dev_clean/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(6,65,348) and mean=136.2
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_dev_clean/log/analyze_lattice_depth_stats.log
steps/decode.sh --nj 10 --cmd run.pl exp/mono/graph_nosp_tgsmall data/dev_other exp/mono/decode_nosp_tgsmall_dev_other
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_nosp_tgsmall exp/mono/decode_nosp_tgsmall_dev_other
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_dev_other/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(16,138,571) and mean=232.9
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_dev_other/log/analyze_lattice_depth_stats.log



Before run_ctc_phone



liujunnan@innovem:/data/home/liujunnan/librispeech/ctc$ ./run.sh
run_ctc_phone.sh: preparing directory for low-resolution speed-perturbed data (for alignment)
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur file is present in data/train_960, because 
... obtaining it after speed-perturbing would be very slow, and
... you might need it.
utils/data/get_utt2dur.sh: data/train_960/utt2dur already exists with the expected length.  We won't recompute it.
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train_960, in data/train_960_sp_speed0.9
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train_960, in data/train_960_sp_speed1.1
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960_sp_speed1.1
utils/data/combine_data.sh data/train_960_sp data/train_960 data/train_960_sp_speed0.9 data/train_960_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh [info]: not combining segments as it does not exist
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 843723 utterances.
fix_data_dir.sh: old files are kept in data/train_960_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in data/train_960, in data/train_960_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960_sp
run_ctc_phone.sh: making MFCC features for low-resolution speed-perturbed data
steps/make_mfcc.sh --cmd run.pl --nj 20 data/train_960_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960_sp
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for train_960_sp
steps/compute_cmvn_stats.sh data/train_960_sp
Succeeded creating CMVN stats for train_960_sp
fix_data_dir.sh: kept all 843723 utterances.
fix_data_dir.sh: old files are kept in data/train_960_sp/.backup
utils/copy_data_dir.sh: copied data from data/train_960_sp to data/train_960_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960_sp_hires
steps/make_mfcc.sh --cmd run.pl --nj 20 --mfcc-config conf/mfcc_hires.conf data/train_960_sp_hires
steps/make_mfcc.sh: moving data/train_960_sp_hires/feats.scp to data/train_960_sp_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_960_sp_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded creating MFCC features for train_960_sp_hires
steps/compute_cmvn_stats.sh data/train_960_sp_hires
Succeeded creating CMVN stats for train_960_sp_hires

run_ctc_phone.sh: aligning with the perturbed, low-resolution data
steps/align_si.sh --nj 20 --cmd run.pl --beam 15 --retry-beam 20 data/train_960_sp data/lang_nosp exp/tri2b exp/tri2b_960_sp_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train_960_sp using model from exp/tri2b, putting alignments in exp/tri2b_960_sp_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2b_960_sp_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_960_sp_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.






Before build tree

