{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSUPERVISED DOMAIN ADAPTATION FOR I-VECTOR SPEAKER RECOGNITION\n",
    "\n",
    "IVECTOR 说话人系统的 无监督 域 自适应 方法\n",
    "\n",
    "# ABSTRACT\n",
    "本文提出一个框架, 基于无监督域自适应PLDA的ivector 说话人识别系统, 给定一个存在的 域外PLDA系统, 我们利用该系统 先聚类 域内 无标签数据, 然后使用这些数据自适应更新PLDA系统参数. 我们探索了两个版本的 凝聚层次聚类方法 使用PLDA系统. \n",
    "使用 利用给予无监督校准的停止准则, 凝聚层次聚类 能够由一个较好的性能.  \n",
    "\n",
    "# INSTRODUCTION\n",
    "在当前的ivector+plda框架下, 需要每个spker 都具有多个不同信道的records, 这样在每个感兴趣(希望使用的)领域数据时, 数据量一般是不足的.  \n",
    "在[9] 中 一个有监督自适应PLDA方法可以解决这个问题, 一个存在的,数据丰富的, 域外PLDA系统, 通过自举自适应, 能够在小数据量的域内标签数据 比 直接在域内训练的PLDA系统由更好的效果.   \n",
    "  \n",
    "在本文中, 我们使用与[9]相同的自适应技术, 但是只需要域内无标签数据.  这样的方法打开了一个大门, 让系统能够使用更大量的域内数据, 因为数据的标签的必须性被消除, 很多无标签的数据都可用了.   \n",
    "我们的方法 利用域外PLDA系统, 对大量的域内无标签数据进行聚类, 这产生了一个域内无标签数据的 标签估计, 然后再利用估计的标签 将PLDA系统参数自适应到域内数据.  \n",
    "\n",
    "section 2 描述系统结构  \n",
    "section 3 介绍无监督自适应框架\n",
    "section 4 描述实验设置 以及结果  \n",
    "\n",
    "# Speaker recognition system\n",
    "ivector length-norm 方法 能够将ivector 变化确定到一个 PLDA能够使用的高斯模型中.   \n",
    "PLDA 系统使用的 生成模型方法 能够快速对 ivector集合直接打分, 在[10] 中提出了一个高效的打分方法.  \n",
    "\n",
    "在ivector 提取, ivector长度归整等系统块中, 都可以进行自适应, 但是效果最明显的还是 PLDA系统块的自适应方法.\n",
    "\n",
    "# UNSUPUERVISED DOMAIN ADAPTION \n",
    "**我们的方法 利用域外PLDA系统, 对大量的域内无标签数据进行聚类, 这产生了一个域内无标签数据的 标签估计, 然后再利用估计的标签 将PLDA系统参数自适应到域内数据.**   \n",
    "三个关键组件: 聚类技术, 确定聚类簇数量, 自适应技术.   \n",
    "\n",
    "## 3.1 clustering \n",
    "\n",
    "[3] 中 通过bayes 方法, 聚类被构造为了一个模型选择问题, 这个方法需要 PLDA系统 对 数据集 的所有分区边际的 边缘似然(模型证据)的评价.\n",
    "然而, 由于组合爆炸问题, PLDA对于分区搜索问题 是不可扩展的, 因此为了降低搜索空间, 我们使用一个启发式凝聚层次聚类方法, 开始每个ivector 为一个分类簇, 然后每步, 根据一个预定义的度量方法 合并两个聚类簇, 这个合并流程, 定义了在全部分区空间的一条路径, 最终聚类通过一个停止准则\n",
    "停止, 这里我们提供两个不同的度量标准 和 停止准则.    \n",
    "\n",
    "\n",
    "### 3.1.1 AHC ivector average\n",
    "凝聚层次聚类 ivector 平均?\n",
    "\n",
    "\n",
    "# 4 EXPERIMENTS\n",
    "## 4.1  Database\n",
    "使用的训练数据是 1 SWB 作为out-of-domain  2 SRE10之前的数据 作为 in-domain  3 SRE10 作为评估集合.\n",
    "\n",
    "## 4.3 Result\n",
    "为了聚焦于 无监督PLDA 自适应系统, in-domain out-domain的ivector 都使用SWB系统得到的 UBM T矩阵 来提取ivector, \n",
    "在Table1 中显示了一个 可思考的性能间隔部分, 在使用out-domain PLDA参数进行打分 和 使用in-domain PLDA进行参数打分. 这说明利用domain自适应挑战是有意义的. 并且提供了一个较大的空白, 来提升无监督自适应的性能影响.\n",
    "**out-domain PLDA 自适应的意义是, 当训练好一个out-domain PLDA, 直接在in-domain评估集上进行评价, 效果5%, 而使用in-domain PLDA在评估集上进行 效果为2%, 这样说明 使用in-domain 能够达到很好的效果,**  \n",
    "\n",
    "**但是当我们有一些无标签的数据nolabel in-domain data时, 没法训练in-domainPLDA 而直接使用out-domain PLDA 又不够好时, 我们可以利用out-domain PLDA 先进性原本数据聚类, 然后得到一个估计标签, 就将原本的数据 标记上了, 这样原始的nolabel in-domain data 就成了 cluster labeld in-domain  data , 然后 在增加上 原始的 out-domain PLDA 就可以 提升效果, 能够近似提高到 直接利用in-domain效果的85%效果**   \n",
    "\n",
    "**AHC score averaging 是更推荐的聚类方法**  \n",
    "\n",
    "\n",
    "## 4.3.3 stopping criterion\n",
    "停止准则 \n",
    "我们已经验证了无监督的校准方法，使用SRE的子集，包含从100到2000个说话人的所有语音剪裁（在每种情况下5个随机抽签），并且在所有情况下，无监督校准停止方法估计错误都在实际说话人数量的20%以内（见图4）。这个估计全SRE集的扬声器数目为2911，即相对误差为23%。此错误小到足以 用聚类结果作为utt的spker标签 进而使用自适应方法.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
