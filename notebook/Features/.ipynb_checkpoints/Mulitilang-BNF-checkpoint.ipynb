{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingually trained bottleneck features in spoken language recognition\n",
    "\n",
    "\n",
    "# Abstract \n",
    "多语言训练一个语言无关的特征表示, 通过使用窄瓶颈层 获得一个 低维特征. 分析了不同类型的特征, 聚焦于实际的BN特征的训练, 分析他们在语种识别中的整合利用. 通过比较 单语种 多语种来训练 BN特征, 我们发现多语种训练BNF的性能. \n",
    "\n",
    "# 1 Instroduction \n",
    "BNF特征 带来了语音信号参数化的 一个质的提升. 这些特征携带了音素内容的信息, 被非线性的压缩进入特征.  \n",
    "尽管有大量的较好结果, 但是特征的提取训练仍然相当耦合与训练语种, 这可以简单的通过多个语种训练的特征均值, 有效改善, 本文也主要聚焦榆次. \n",
    "\n",
    "本文主要描述 多语言BNF的一些分析, 以及详细的对比结果. \n",
    "\n",
    "1  单语种 多语种训练的 BNF 的差异   \n",
    "2  不同的NN结果, 以及输出层设置.  \n",
    "3  使用的是MFCC(SDC)来训练BN\n",
    "\n",
    "## 1.1 related work\n",
    "\n",
    "包含多种NN特征的演进, 其中现在感觉有效的有: 可以对短时speech 使用特定分类器.   \n",
    "\n",
    "  The use of Long Short Term Memory (LSTM) cells to directly classify languages has been investigated by\n",
    "Gonzalez-Dominguez et al. (2014); Zazo et al. (2016). The advantage of recurrent architectures is in natural handling of time context by memorizing internal state over time and also very small number of parameters compared to stan- dard i-vector system. **As it happens with other DNN approaches, this technique outperforms conventional i-vectors only in short durations.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 BNF\n",
    "BNF  SBNF 是两种特征\n",
    "SBNF 叫做 stack BNF 是将多帧上下文BNF 拼接之后再进行NN训练 取得瓶颈层作为的特征, 效果更好. \n",
    "\n",
    "# 3 Multilangual training of BNF\n",
    "1 one softmax \n",
    "2 block softmax \n",
    "**block softmax 效果比 one softmax , 具体分析在 Section 5.4**   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5  Result \n",
    "# 5.3  fusion of mono- and multi-langual system \n",
    "经过分析, 多个单语种BNF+ 多语种BNF + SDC 的熔合 效果最好, \n",
    "MFCC(SDC) 对于短时语段效果有一些提升. \n",
    "\n",
    "**但是 实际使用中 可以使用  BNF + SDC 作为特征.**\n",
    "\n",
    "**Such behavior can be expected, as a system based on spectral features may fetch valuable information when the duration of test segment is limited to just a few seconds**\n",
    "\n",
    "\n",
    "# 6 Conclusion\n",
    "在本文工作中, 尝试了多语种训练NN 获得丰富信息的特征, 我们显示了这样更丰富信息特征具有比单语种训练的特征更好的性能.   \n",
    "并且也发现, 多语言熔合NN的特征 也是对 多个单语言系统NN提取之后熔合的特征的一个补充, 这也更佳确定了 多语种NN训练 能够获得比 简单的多个系统之后熔合更好的效果.   \n",
    "one-softmax 也是足够好的, 但是 one-softmax的输出层 希望区分不同语种间相似的音素 也是有问题的, 这加重了我们使用 通用音素的想法(Anderson et al. (1994))  \n",
    "\n",
    "本文较大篇幅描述 多语言训练的BNF, 我们分析了几个主要的陷阱, 包括以senones为目标, 以及选择输入的上下文内容, 结果主要以语种识别准确率衡量, 结果显示 SBNF 对于语音识别 效果更好, 对于 语种识别 BNF 在增加了上下文长度时, 效果和SBNF差不多.  \n",
    "\n",
    "单一语种识别的结果显示, 单语种训练的强耦合性, 即 语种特定训练的BNF 能够获得最好的效果, 多语言BNF在独立语种工作的更好.  \n",
    "\n",
    "    \n",
    "\n",
    "最终说明,  Multilangual 效果好, block-softmax训练方法比 one-softmax好, BNF在 语种识别中 增加上下文输入 效果也不差, 最好的还是 SBNF \n",
    "BNF + SDC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
