* Data types in "nnet3" setup
** Objectives and background
   nnet1 nnet2 都是基于Component 对象构建的神经网络.
   Component 构建layer, 使用一个窍门 一个layer 使用一个affine+nonlinearity构建.实际两个Component构建一个layer.
   Component 具有propagate backprop 函数, 都是基于minibatch的函数.
   
   两者都不仅仅支持 nonlinearities的线性序列.
   nnet1 可以使用component within component 构建复杂的网络结构
   nnet2 有一个time-index的时延概念 来支持 时序上特征的剪切拼接 进而直接作为框架的一部分
   这通过将隐藏层进行切片剪切 能够支持TDNN.
   nnet3 能够支持nnet1 nnet2中的topo结构, 并且用一种更自然 以配置文件驱动的机制, 我们不需要coding 就能够支持
   绝大多数想要的结构.

   
** outline of approach
   nnet3 不像nnet1 nnet2 结构只有一个线性的component序列, 而是一个更通用的graph结构.
   1 一系列component, 没有固定顺序
   2 一个graph结构, 描述component的结构

   Each node in that acyclic graph will be identified by the node in the neural network graph (i.e. the layer of the network) together with a number of additional indexes: time (t), an index (n) that indicates the example within the minibatch (e.g. 0 through 511 for a 512-example minibatch)

   graph 通过name 引用components.
   利用config-file 来描述一个 nnet3的 数据流图,
   Components + graph + inputs provided + outpu requested.
   这四个部分 构建了一个 计算图 -- ComputationGraph. 是一个有向无环图.
   

** Basic data structures in nnet3
   ComputationGraph中的node  identified  
   对应为:
       nnet中的一个层node-in-network + index (n)(代表minibathch中的第n个examples) + time(t) + 额外的index (x) 现在无用.

   Cindex = (node-index, Index)
   Index = (n, t, x)
   *where the node-index is the index corresponding to a node in the neural network (i.e., the layer)*
   实际创建的计算图 在编译期间就表现为 基于 Cindex的有向无环图.
   

*** Indexes (n, t, x)
    Indexes 对应为 Matrix中的rows 
    实际就是对应为 训练样本中的各个sample1 sample2 sample ... samplen
    eg:
    1 对于简单 前馈神经网络, 不处理时间概念 Indexes描述一批训练样本就是
    [ (0, 0, 0)  (1, 0, 0)  (2, 0, 0) ... ]
    其中 t 保持不变,不具有时间性.
    
    2 如果 我们使用相同的 前馈神经网络 解码单独一句 utterance.Indexes就只会
    在 t slot变化
    [ (0, 0, 0)  (0, 1, 0)  (0, 2, 0) ... ]
    这样来对应 Matrix中的rows ??? 没见到实际应用,难道对训练和解码过程Indexes
    对应Matrix的方法不一样?

    3 如果在一个具有时间上下文相关性的网络中, 对于靠前的layers中在训练中
    需要 t 值变化, 我们可以会遇到多个 n t 都会变化的Indexes list.
      [ (0, -1, 0)  (0, 0, 0)  (0, 1, 0) (1, -1, 0) (1, 0, 0) (1, 1, 0) ... ]
    
       
    内部按 n t x进行排序, 并且 t x都可以简略, 当具有 vector<Indexes>, 表示为如下
    [ (0, -1:1) (1, -1:1) ... ]

*** Cindex (node-index, (n, t, x))
    node-index 是nnet网络的node节点index. 
    Cindexes 对应计算图中的一个特定计算.
    Cindexes 也描述为某个确定tensor,通过依赖进行计算得到的结果tensor.
    其中
    nodex-index 描述nnet整体中的层node
    n 描述层node中的 sample-index
    t 描述层node中的 sample-index 下的 t frame

*** ComputationGraph
    ComputationGraph 是基于Cindexes 的一个有向图, 每个Cindex都以其他Cindexes为依赖.
    ComputationGraph 保存了Cindexes 的数组.
    cindex_id 是 Cindexes 数组的索引index. 使用起来高效
    
*** ComputationRequest 计算目标
    ComputationRequest 描述了一系列的 input output Cindexnode, 
    inputnodes 描述了哪些indexes对应的vector-valued quantities 被用于进行计算
    outputnodes 描述了哪些indexes 需要被计算.
    
    有了计算目标, 就能够根据图 进行计算.

*** NnetComputation 
    通过ComputationRequest描述了的计算目标 + nnet结构中的graph计算流图 构建的NnetComputation流程.
    包含一些列的 commands,每个命令都是一个基于矩阵变量上执行的propagate backprop操作.
    
*** NnetComputer
    nnet 计算子
    作用是实际执行NnetComputation计算步骤.
    这部分就是循环计算更新参数, 因为大部分构建流程的步骤都在 NnetComputation的 compilation 和 optimization中完成了


** Neural networks in nnet3
   上面概览的介绍了 nnet3框架.
   详细介绍框架, 组件如何组合 以及 如何表示像t-1那样的依赖关系.
   
*** Components
    Propagate  Backprop
    input output 的每个row 是对应的, 并且对应与 indexes中的每个对象
    
    properties 属性
    返回一个 bitmask的flag属性 ComponentProperties
    描述component具有的不同特性.
    
    component 不再用来处理 帧切片拼接等工作, 这些工作使用Descriptor来实现.

*** Neural network nodes (outline)
    We previously explained that a neural net is a collection of named Components together with a graph on "network nodes", 
    but we haven't yet explained what a "network node" is.

    四种可能的 nodes
    enum NodeType { kInput, kDescriptor, kComponent, kDimRange };
    kComponent 是模块
    kDescriptor 是胶水, 并支持一些特殊性 如 切分 循环 以及 output

*** Neural network config files
    kaldi
    
*** Descriptors in config files
    描述了 Descriptor 但是还是不太理解.

*** Descriptors in code
    实际中Descriptor结构, 是一个层次性的结构, 用来粘合不同component
    每个Descriptor 是以一个component的输出作为输入的.
    并且Descriptor能够描述 自己代表的计算步骤 是否能够执行computation.
    
*** Neural network nodes 
    enum NodeType { kInput, kDescriptor, kComponent, kDimRange };
    
*** Neural network  Nnet
    class Nnet {
    public:
    ...
    private:
    std::vector<std::string> component_names_;
    std::vector<Component*> components_;
    std::vector<std::string> node_names_;
    std::vector<NetworkNode> nodes_;
    
    };

*** NnetComputation
    代表一个编译完成的计算图, 包含一些列的 Commands 以及必须的一些信息
    定义了很多Command

    enum CommandType {
    kAllocMatrixUndefined, kAllocMatrixZeroed,
    kDeallocMatrix, kPropagate, kStoreStats, kBackprop,
    kMatrixCopy, kMatrixAdd, kCopyRows, kAddRows,
    kCopyRowsMulti, kCopyToRowsMulti, kAddRowsMulti, kAddToRowsMulti,
    kAddRowRanges, kNoOperation, kNoOperationMarker };
    
    struct Command {
    CommandType command_type;
    int32 arg1;
    int32 arg2;
    int32 arg3;
    int32 arg4;
    int32 arg5;
    int32 arg6;
    };
    一个实际的Command 包含具体的 command_type 和多个参数
    参数一般是引用具体的 matrix 或者 Component.
    
    struct NnetComputation {
    ...
    std::vector<Command> commands;
    std::vector<MatrixInfo> matrices;
    std::vector<SubMatrixInfo> submatrices;
    // used in kAddRows, kAddToRows, kCopyRows, kCopyToRows.  contains row-indexes.
    std::vector<std::vector<int32> > indexes;
    // used in kAddRowsMulti, kAddToRowsMulti, kCopyRowsMulti, kCopyToRowsMulti.
    // contains pairs (sub-matrix index, row index)- or (-1,-1) meaning don't
    // do anything for this row.
    std::vector<std::vector<std::pair<int32,int32> > > indexes_multi;
    // Indexes used in kAddRowRanges commands, containing pairs (start-index,
    // end-index)
    std::vector<std::vector<std::pair<int32,int32> > > indexes_ranges;
    // Information about where the values and derivatives of inputs and outputs of
    // the neural net live.
    unordered_map<int32, std::pair<int32, int32> > input_output_info;
    bool need_model_derivative;
    // the following is only used in non-simple Components; ignore for now.
    std::vector<ComponentPrecomputedIndexes*> component_precomputed_indexes;
    ...
    };

    
    
    
    
    
   

   
   
   
   
   

   



* Compilation in the "nnet3" setup 
  
** Overview of Compilation
   Compilation 将Nnet和ComputationRequest作为输入, 输出一个NnetComputation.

   NnetComputation 就是一个完整的计算. 是一个过程结构.
   ComputationRequest 包含 作为目标输出的indexes 和 可用的作为输入的indexes. 



** Creating the computation graph

*** Details of ComputationGraph
    struct ComputationGraph {
    // The mapping of cindex_id to Cindex.
    std::vector<Cindex> cindexes;
    
    // For each Cindex this tells us whether it was provided as an input to the
    // computation.
    std::vector<bool> is_input;
    
    // dependencies[cindex_id] gives you the list of other cindex_ids that this
    // particular cindex_id directly depends on to compute it.
    std::vector<std::vector<int32> > dependencies;
    private:
    // Maps each Cindex to an integer cindex_id: reverse mapping of "cindexes".
    // Must be accessed via the GetCindexId() function.
    unordered_map<Cindex, int32, CindexHasher> cindex_to_cindex_id_;
    };
    
    is_input 可以通过判断一个node 的 type 是否是一个kInput来确定, 但是这么设计并不冗余
    因为 is_input 设计出来 以便能够让已经计算好的computed 的component 作为输入, 然后这样
    能够实现 online decoding 的设想.
    
*** Building the ComputationGraph
    根据数据成员可以看出 ComputationGraph是用来描述各个Cindex的依赖的.
    根据依赖关系, 构建了一个完整的计算流图.  Cindex 就实际对应一个就算节点.
    std::vector<std::vector<int32>> dependencies;

    并将Cindex ---- cindex_id 互相对应, 便于使用cindex_id 找到Cindex
    
**** intruduction
    ComputationGraphBuilder 负责构建 ComputationGraph
    process:
    1 从network的 目标输出 output 开始
    2 计算 output-node 的 dependences , 并将这些dependences加入计算图,
    3 直到dependence 都达到 input node 否则, 继续递归反向寻找dependence 并加入到计算图
    
    最终在都成为了input node 对应的 Cindexes 应该都是已经在ComputationRequest中提供好了的

    算法就是 递归找寻依赖Cindex, 将Cindex添加入ComputationGraph的过程.
    
**** Basic algorithm

     1, First follow back all possible dependencies from 
     the output using the GetDependencies() functions of Descriptors and Components.
     递归找寻依赖

     2, In the opposite direction, starting from the input, 
     work out which Cindexes are computable (using IsComputable()), 
     and prune back the dependencies to just those that participate in the computation.
     反向评估每个Cindex是否可计算computable

     3, Check that all requested outputs were computable.
     检查是否requested-output都是computable

     4, Prune away all cindex_ids that are not actually necessary to compute the outputs.
     剪枝掉实际不必要的Cindex.

**** Motivate for the algorithm we use
     类似循环神经网络这样的结果, 当一个node 依赖于 时延的 t-1 node 时
     而基本算法中, 是在back添加一个dependence是否可计算时候, 才去查看是否能够计算
     所以基本算法 会出现问题??

**** The algorithm we use
     为了避免 RNN中的-索引依赖 不存在问题, 会使用 
     enum ComputableInfo {
     kUnknown = 0,
     kComputable = 1,
     kNotComputable = 2,
     kWillNotCompute = 3
     };
     然后通过标记的使用 避免无限循环.?

     ComputationGraphBuilder 保持两个queues
     1 对Cindexes 还没有添加他们依赖到graph 中的Cindexes
     2 computable_queue_ 对Cindexes 需要重新评价是否是computable 通过更新他们的ComputableInfo 如果一个Cindex的ComputableInfo更新了
     那么需要递归向上检查依赖他们的Cindex是否需要更新. 就通过将对应的Cindex -> computable_queue_
     
**** Interface of ComputationGraphBuilder
     几个接口函数

     void Compute()  执行初始化 计算computation
     void AllOutputAreComputable
     void Prune()    剪掉不必要的Cindex.

      
     
** Organizing the computation into *steps*
   经过上面的builder ComputationGraph, 我们已经具有了执行计算所需要的所有信息
   按照ComputationGraph的topo结构排序Cindexes, 独立根据对应依赖计算每个Cindex, 这样就可以进行流图计算了.
   !! 
   但是这样做很低效, 矩阵运算在越大时计算效率越高,如果都是小计算会影响效率, GPU时尤其如此
   
   将computation组织为step的过程就是, 安排所有cindex_ids 为一系列steps的过程.
  
*** Introduction to *steps*
    因为逐个进行Matrix计算, 十分低效, 当使用GPU时尤其是, 所以希望能够将Cindexes分为batch
    *以便同batch的Cindexes可以同时进行计算, 这样一个batch 叫做一个 step.*
    *并且这样的一个step 粗略上就对应为是NnetComputation中的一个Command.*

    所以最重要的是 怎么整理 cindex_ids 为一系列的steps, 且需要满足一些条件属性.
    1 一个step中的所有cindex_ids 都对应为graph中的一个node
    2 一个cindex_ids的所有依赖 必须在之前的steps 中计算完成

*** Creating the sequence of steps (basic algorithm)
    
    A, 将对应为Input Output的Cindexes 分开, 按照在ComputationRequest中的顺序进行排序.先放在一边
    B, 处理哪些非input output的Cindexes
          1 将这些剩下的Cindexes 组织为 phases 的多个集合. 
          其中第一个phases中的Cindexes都只依赖自己
          其他的n个phases中 保存所有依赖之前n-1 phases中的Cindexes的Cindexes.
          2 从每个phase中去掉所有 不是kComponent的Cindexes (非kComponent 就是 kDimRange 和 Component-Input nodes) .
          3 按照Index 的排序规则排序steps.
          4 对component-input node 创建steps
          5 对dim-range node 创建steps
    C, 排序所有steps, input最先, 然后接下来的steps ,output steps 最后.
    
    基本算法的问题是 
    最终将产生很多steps
    例如假设有一个循环层, 并后面立刻接一个前向层,循环层会被分割为很多steps
    因为这里是有time index, 但是上面的算法会分割全连接层的计算为很多steps 因为
    这些Cindexes????
    
*** creating the sequence of steps  (actual algorithm)
    为了处理RNN这样的结构 并且不希望产生过多的计算steps..
    ??????
    
    
          
    
** Class Compiler
   
*** Introduction to class Compiler
    Compiler 全面负责 将 ComputationRequest 和 Nnet 转化为一个 NnetComputation
    内部首先创建一个 ComputationGraph 和使用上面介绍过的函数创建一些列的steps 
    
*** Creating the computation
    
    void Compiler::CreateComputation(const CompilerOptions &opts,
                              NnetComputation *computation) {

      # 使用Builder 构建 ComputationGraph
      ComputationGraphBuilder builder(nnet_, request_, &graph_);
      builder.Compute();
      builder.Prune();
      
      # 组织Computation 为 steps.....
      // see function declaration's comment for meaning of "phases".
      std::vector<std::vector<int32> > phases;
      ComputeComputationPhases(nnet_, graph_, &phases);
      std::vector<std::vector<int32> > steps;
      ComputeComputationSteps(nnet_, request_, phases, &graph_, &steps);
      phases.clear();


      # Compiation process
      CreateLocationInfo(steps);
      std::vector<bool> deriv_needed;
      ComputeDerivNeeded(steps, &deriv_needed);
      CreateStepInfo(deriv_needed, &steps, computation);
      AddCommands(deriv_needed, computation);

      if (opts.output_debug_info)
         OutputDebugInfo(computation);
    }



*** Setting up the location information
    CreateLocationInfo() set a mapping cindex_id_to_location_, 映射每个cindex_id to localtion. 
    location 是一个 pair<step-index, matrix-row-index>. 
    matrix-row-index 对应为 对应step在cindex_ids的cindex_id.
    
    先前提到理论上 cindex_ids 可以对应为一个表示component输入的 kDescriptor的网络节点.???
    
    我们会考虑 location information 位置信息的很多种不同的位置信息.
    cindex_id_to_location_ 保存了 location pair<step-index, matrix-row-index>
    还有其他的有:
    submat-locations    pair<submatrix-index, row-index>
        submatrix-index 是Computation中submatrices向量中的索引.

    Once we have decided where the values and derivatives for each of the steps live, 
    we will be able to compute the "submat-locations".
    确定 每个step的 值和导数的存在性. 就可以计算submat-locations.
    
*** Checking whether derivatives are needed
    每个steps 都需要判断是否需要derivatives.
    有一个根据依赖关系 来判断是否需要 derivatives的rules
    具体见 kaldi

*** Computing the StepInfo
    每个steps都具有一些关联的信息 info
    Compiler保存一个 steps_  --- std::vector<StepInfo> 保存所有信息.

class Compiler {
   ...
  struct StepInfo {
    int32 node_index;  // network-node index
    bool is_input;  // true if step corresponds to an input to the computation.
    int32 value;  // sub-matrix index of value that this step outputs.
    int32 deriv;  // sub-matrix index of derivative at the output of this step (or zero).
    int32 precomputed_indexes_index;  // ignore; only relevant for non-simple Components
    std::vector<Index> output_indexes;      // Indexes that this step outputs.
    std::vector<int32> output_cindex_ids;   // cindex_ids corresponding to the above.

    // If this component is of type kDescriptor (and note that the top-level
    // Descriptor is a concatenation over >= 1 parts), then we set value_parts
    // to a list of submatrix-indexes, each for the corresponding part of the
    // value.  If there is only one part, it will have one element which will be
    // the same as "value".
    std::vector<int32> value_parts;
    // deriv_parts is as "value_parts", but for parts of the derivative (only
    // set up if deriv != 0.
    std::vector<int32> deriv_parts;

    // for nodes corresponding to descriptors, input_locations_list will contain
    // information about the inputs to this descriptor, telling us for each row
    // of the matrix what other matrix rows it is a summation over.  this is a
    // quantity indexed[part-index][row-index], then a list of pairs (step,
    // row-index), that we store here to avoid computing it twice in forward and
    // backprop.
    std::vector<std::vector<std::vector<std::pair<int32,int32> > > > input_locations_list;
  };
  std::vector<StepInfo> steps_;
  ...
};

    node_index is_input 变量都可以通过ComputationGraph 和 ComputationRequest直接计算出来.
    output_cindex_ids 只是此step 包含的cindex_ids 的copy
    output_indexes 可以通过 output_cindex_ids 和 ComputationGraph计算.
    value deriv 都是我们需要为step申请空间的sum-matrix ids 
    
    
**** Allocate the matrices and submatrices (background)
    Matrix and SubMatrix indexes, 以及如何申请他们
    matrix index 是 NnetComputer中 matrices_的索引index, 也是NnetComputation中matrices的索引(这里只保存了大小)
    summatrix index 是NnetComputation中 submatrices的索引,表示一个特定matrix的 特定row column范围的submatrix
    无论什么时候尽可能的使用submatrix-index 代替使用matrix-index. 这样尽可能的避免两种index的使用.
    
    struct NnetComputation {
  ...
  int32 NewMatrix(int32 num_rows, int32 num_cols);
  int32 NewSubMatrix(int32 base_matrix, int32 dim_offset, int32 dim);
  ...
};
    NewMatrix 申请一个新的matrix和一个sub-matrix指代整个matrix,并返回sub-matrix
    NewSubMatrix 申请一个sub-matrix 对应一个存在的matrix的column范围 sub-matrix

**** Allocating matrices and submatrices for StepInfo
     所有的steps 除了KDimRange 都需要value Matrix
     kDescriptor类型的steps 对value 和 derivative 会具有不同parts submatrix .
     每个part 对应一个submatrix.

**** The input locations list
     对Descriptor的每个part. 调用ComputeInputLocationsList().
     this_info.input_locations_list[p] (p is the part index), is of type std::vector<std::vector<std::pair<int32, int32> > >
     告诉我们 从哪里获得 用来计算Descriptor该part的数据.
     首先通过matrix的row-index索引(和step对应cindex_ids的索引一样)
     然后是一列 locations <step-index, row-index> 
     因为一个Descriptor只能表示一个 不加权的 matrix rows累和, input_locations_list实际包含了我们需要的所有信息.

     ComputeInputLocationsList(), you'll see the following lines:

     std::vector<Cindex> input_cindexes;
     CindexSet cindex_set(graph_);
     bool ans = descriptor.IsComputable(index, cindex_set, &input_cindexes);
     KALDI_ASSERT(ans);
     
     回忆到 IsComputable() 会返回输出 在计算中需要的Cindexes. 会感到惊讶为什么要调用这个函数, 
     完全可以直接依赖于在ComputationGraph中list的dependences, 但是因为ComputationGraph 会list
     一个Cindex的所有dependences,但是我们有时候只需要 a part of Cindex 一部分的计算. 
     graph 没有按part分割依赖.

*** Computing the input_output_info
    AddCommands(deriv_needed, computation)
    -----
    SetInputOutputInfo(computation);
    负责建立NnetComputation 的 input_output_info 结构
    unordered_map<int32, std::pair<int32, int32> > input_output_info;
    包含了 input output的存在位置信息,以及对应导数存在位置
    
    input_output_info 是从 node-index 对应 pair<value-matrix-index, derivative-matrix-index>的映射.

*** Allocating the matrice
    AddCommands(deriv_needed, computation)
    -----
    AllocateMatrices(computation);
    向computation中增加command, 为了申请和归零所有Computation的matrices成员, 会使用kAllocateMatriZeroed command
    参数为 对应matrix的index.
    
*** The forward computatio Command!!
    前向计算命令的建立
    AddCommands(deriv_needed, computation)
    -----
    int32 num_steps = steps_.size();
    for (int32 step = 0; step < num_steps; step++)
        DoForwardComputation(step, computation);

    为computation的前向部分增加command.

void Compiler::DoForwardComputation(int32 step,
                                    NnetComputation *computation) const {
  const StepInfo &step_info = steps_[step];
  const NetworkNode &node = nnet_.GetNode(step_info.node_index);
  switch (node.node_type) {
    case kInput: case kDimRange: break;  // Nothing to do.
    case kComponent:
      AddPropagateStep(step, computation);
      break;
    case kDescriptor:
      DoForwardComputationDescriptor(step, computation);
      break;
  }
}

**** Forward computation for componnents
     如果step是Component, 
     AddPropagateStep()
     增加一个kPropagate类型的 command
     
     并且AddPropogate也负责增加保存每个Component统计量的command.
     Component统计量是用来检测过饱和的非线性层???

     NnetComputation::Command c(NnetComputation::kPropagate,
                             node.u.component_index,
                             step_info.precomputed_indexes_index,
                             input_submatrix_index,
                             output_submatrix_index);
    computation->commands.push_back(c);
    if (request_.store_component_stats) {
    const Component *c = nnet_.GetComponent(node.u.component_index);
      if (c->Properties() & kStoresStats) {
        NnetComputation::Command c(NnetComputation::kStoreStats,
                                 node.u.component_index,
                                 output_submatrix_index);
        computation->commands.push_back(c);
      }
    }

    
**** Forward computation for Descriptor(top-level)
     Descriptor的建立过程比Component的复杂

void Compiler::DoForwardComputationDescriptor(
  int32 step, NnetComputation *computation) const {
  int32 num_parts = steps_[step].value_parts.size();
  for (int32 part = 0; part < num_parts; part++)
    DoForwardComputationSumDescriptor(step, part, computation);
}

void Compiler::DoForwardComputationSumDescriptor(
  int32 step, int32 part_index, NnetComputation *computation) const {
  const StepInfo &step_info = steps_[step];
  std::vector<std::vector<std::pair<int32, int32> > > submat_locations_list;
  ComputeValueSubmatLocationsList(step_info.input_locations_list[part_index],
                                  &submat_locations_list);
  int32 value_submatrix_index = step_info.value_parts[part_index];
  DoForwardComputationFromSubmatLocationsList(
      value_submatrix_index,
      submat_locations_list,
      computation);
}

**** Forward computation for Descriptor (SplitLocations)
     SplitLocation 十分重要, 输入为 submat_list , 通过matrix-row索引, 是一系列将要被累和起来的输入locations.
     SplitLocatios 为所有lists增加(-1,-1)?? 保证都具有相同长度.
     然后将 Vector of lists 转化为 list of vector.
     例如,我们有一个1000rows的matrix,SplitLocations()的输入是 submat_lists 都是不长于2的
     SplitLocations会输出一个长度为2的向量, 每个元素都是长度为1000的元素. 如果原本某个list的长度小于2,对应输出中会包含增加的 (-1,-1)
     
     SplitLocations 希望确保从相同submatrix中的输入 尽可能都和输出的vector相同大小??.
     这样能够保证我们使用更有效的命令.
     这样SplitLocation为了更有效就有可能输出比较多的vectors
     
     
**** Forward computation with DoForwardComputationFromSubmatLocations
     ..................

**** Marking the end of the forward computation
   
     当建立了所有前向计算的命令之后, 需要增加一个 Mark command
     computation->commands.push_back(
         NnetComputation::Command(NnetComputation::kNoOperationMarker));
     执行代码 会检测 这个marker, 以便知道何时computation的前向计算完成, 准备开始反向传播部分.
     
*** The backward computation
    ......... kaldi

    
    
    

   

   
   
   
   
   


   
   
   
   





