{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I2R-NUS Submission to Oriental Language Recognition AP16-OL7 Challenge\n",
    "\n",
    "# Abstract \n",
    "本文对 AP16-17 OLR 挑战中 李海洲 等 提交的最佳系统进行详细描述 以及分析.  \n",
    "\n",
    "system = subsys-ivector  + subsys- GMM-SVM   \n",
    "\n",
    "Feature: Bottleneck feature \n",
    "Central: language-dependent UBM GMM-SVM , and ivector polynomials expansion(多项式膨胀) SVM .  \n",
    "Fusion:  FoCal Toolkit 用来fusion subsystem.   \n",
    "\n",
    "significant improvement , EER 0.4%(经验误差) 1.09%(测试误差)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction \n",
    "该方案是两重子系统熔合.  \n",
    "First, 使用BNF 替代MFCC-SDC,  用来提取 ivector 和 GMM supervector, BNF 特征就会导致巨大的性能提升.   \n",
    "GMM-SVM supervector 方案中, 使用 Language dependent GMM策略, 来提取 Language dependent supervector.  \n",
    "(这里并不是 Language denpendent UBM!!! 是GMM!!)\n",
    "Second, 使用 pair-wise SVM 分类器 训练模型, 并提升 pair-wise 识别性能.    \n",
    "打分级别校准 以及 FoCal 熔合 ivector 和 GMM-supervector 打分 形成最终打分结果.  \n",
    "(那么 ivector, GMM-supervector 的 UBM 是否使用的也是 language dependet ?)   \n",
    "\n",
    "SECTION 2 , DataBase .\n",
    "SECTION 3 , front-end Feature  extraction. \n",
    "SECTION 4 , 描述分类器.  \n",
    "SECTION 5 , 描述得分校准, 以及 FoCal 熔合.  \n",
    "SECTION 6,7, 结果.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Front end Feature extraction\n",
    "## 3.1 BNF \n",
    "语种识别的性能, 通过使用一个鲁棒性的特征 能够提升巨大的性能, 鲁棒性的特征 是 能够捕获语种特性, 同时抑制 类似噪音 和 说话人特性的特征.  \n",
    "例如BNF 就是这样的一种特征. 这里概述的描述下 BNF提取器的训练过程.   \n",
    "1 language-independent GMM-HMM 系统 训练来识别 语言无关的13361个senone labels.  Feature: MFCC\n",
    "2 当获得得到一个GMM-HMM的 senone label对齐, 就使用DNN 替代GMM-HMM.   DNN Feature: FBANK + PITCH, 并加上帧拼接.   \n",
    "3 最终 倒数第二层 是一个瓶颈层, 作为特征输出. \n",
    "\n",
    "## 3.2  BNF VAD\n",
    "我们使用谱减法, 来帮助实现 静音检测, BNF特征 看来还是需要 VAD 的, 但是具体怎么实现呢?\n",
    "   \n",
    "**HOW [8] ---------------------------------------------------------------**   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 SYSTEM DESCRIPTIONS \n",
    "## 4.1 ivector SVM  \n",
    "1 64 BNF     \n",
    "2 VAD    \n",
    "3 512 UBM   \n",
    "4 600 ivector   \n",
    "5 600 ivector 然后 通过 polynomial 二阶多项式基函数 扩展为 180901 维, ivector-polynomials    \n",
    "**HOW-----------------------------------------------------------------------**   \n",
    "6 减 均值 , unit-formed归一化 得到 ivector-poly-unit.  \n",
    "$$ iv_{new} = \\frac{iv - \\mu_{element} }{|| iv - \\mu_{element}||} $$\n",
    "7 SVM 分类.  \n",
    "\n",
    "\n",
    "## 4.2 GMM-SVM System \n",
    "1 64 BNF \n",
    "2 训练 7个(Language Cnt) 512 GMM-UBM(Language-denpendent)   \n",
    "3 GMM-UBM的均值构成超矢量$S_i$, 正则化     \n",
    "$$ S_{i_{new}} = \\frac{S_i - \\mu_{element} }{|| S_i - \\mu_{element}||} $$  \n",
    "4 每个utt 根据对应的512GMM-UBM, 生成一个 32768 = 64(BNF) x 512(UBM Component Cnt) 的 supervector .   \n",
    "5 最终得到 7 个集合的语种相关的 GMM supervector.    \n",
    "6 然后训练SVM\n",
    "7 测试时, 一个test utt 会得到 7个supervector, 然后分别得到对应得分, 最终得分均值作为GMM-SVM 子系统得分? 这里有问题, 这样的得分没有语种信息啊.   \n",
    "**HOW----------------------------------------------------------------------**   \n",
    "\n",
    "## 4.3 SVM Classifier \n",
    "pair-wise 策略 训练 SVM 语种模型.  \n",
    "**HOW[9]**    \n",
    "pair-wise 是 多个类别目标,  两两目标之间进行判别分类.  那么对于 7个分类目标, 最终要训练 21个SVM  21=(7 x 6)/2 (排列组合)    \n",
    "    \n",
    "Train:  \n",
    "$$ f_{m,i} = SVM_{train}(\\Phi_m | \\Phi_i ), i != m  \\tag{4}$$\n",
    "   \n",
    "Test:   \n",
    "test supervector $S_i$, 对所有 21 个SVM分类器进行打分评价, 对 k-th 个语言的打分为 所有包含k-th language 的 6个分类器,中打分最小的得分值. 就是$S_i$ 识别为k语言的最可能得分(该得分最终是对比最不可能语言的得分比)    \n",
    "**HOW[10]---------------------------------------------------------------**    \n",
    "$$ Socre_{i-for-kth} = min \\Big( f_{k, j}(S_i)\\Big) , j=1..N, j!=k \\tag{5}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Scorce Calibration and Fusion \n",
    "## 5.1 Scorce Calibration and Fusion \n",
    "本任务, 使用了 1-vs-rest 策略训练不同的子系统, 因此 M 个子系统, N个语种 最终会有 MN个分类测试, 测试一个$S_i$属于某个语种, 每个$S_i$测试具有M个分类器. 在[7]中 测试了多种不同的 score Calibration 和 Fusion 技术. 最终, 虽然线性熔合方法 简单, 但是线性融合方法 高效, 实现简单, 并且 一般效果很好.   \n",
    "Score Fusion:    \n",
    "$$ S_l = \\sum_{m=1}^{M} \\alpha_m x s(m, l) + \\beta \\tag{6} $$ \n",
    "$\\alpha_m$ 是 m 子系统的权重, $\\beta$ 是n维偏移向量, l 代表一个trial测试.   最终熔合参数 通过 FoCal Multi-Class Toolkit[5] 最小化 $C_{llr}$ 获得.  \n",
    "  \n",
    "  \n",
    "最终每个语种的测试结果, 根据bayes原理, 通过对数似然比[11]计算得到:   \n",
    "$$ S_{DET}(L_n) = log\\Big[\\frac{exp(s_n)}{(\\frac{1}{N-1})  \\sum_{k!=n} exp(s_k)}\\Big] $$\n",
    "$$ S_{DET}(L_n) = s_n - log\\Big(\\frac{1}{N-1} \\sum_{k!=n} exp(s_k) \\Big) $$\n",
    "因为 $ C_{miss} = C_{fa} = 1 , P_{target} = 0.5 $ , 最终检测门限就是0, 当$S_{DET}(L_n)$ > 0, 说明为对应语种.    \n",
    "本次实验, 也试验了 进行后端得分处理 与 不进行的比较.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Conclusion \n",
    "1 BNF 是一个提升重点   \n",
    "2 scores Calibration 和 FoCal 熔合策略 也是一个提升重点.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
